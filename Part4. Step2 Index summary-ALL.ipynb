{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dd425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import onekey_algo.custom.components as okcomp\n",
    "from onekey_algo import get_param_in_cwd\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "model_names = ['Clinic', 'Habitat', 'Pathology', 'Ensemble_CH', 'Ensemble_CP', 'Ensemble_HP', 'Ensemble_CHP', 'MHA_CHP']\n",
    "# 获取配置\n",
    "task = get_param_in_cwd('task_column') or 'label'\n",
    "bst_model = get_param_in_cwd('sel_model') or 'LR'\n",
    "labelf = get_param_in_cwd('label_file') or os.path.join(mydir, 'label.csv')\n",
    "group_info = get_param_in_cwd('dataset_column') or 'group'\n",
    "\n",
    "# 读取label文件。\n",
    "labels = [task]\n",
    "label_data_ = pd.read_csv(labelf)\n",
    "label_data_['ID'] = label_data_['ID'].map(lambda x: f\"{x}.nii.gz\" if not (f\"{x}\".endswith('.nii.gz') or  f\"{x}\".endswith('.nii')) else x)\n",
    "label_data_ = label_data_[['ID', group_info, task]]\n",
    "label_data_ = label_data_.dropna(axis=0)\n",
    "\n",
    "ids = label_data_['ID']\n",
    "print(label_data_.columns)\n",
    "label_data = label_data_[['ID'] + labels]\n",
    "label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ee2cf",
   "metadata": {},
   "source": [
    "# 训练集-Nomogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5002786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from onekey_algo.custom.components.comp1 import normalize_df\n",
    "\n",
    "subset = 'train'\n",
    "Clinic_results = pd.merge(pd.read_csv(f'./results/Clinical_RandomForest_{subset}.csv', header=0), label_data, on='ID', how='inner')\n",
    "Habitat_results = pd.merge(pd.read_csv(f'./results/Habitat_RandomForest_{subset}.csv', header=0), label_data, on='ID', how='inner')\n",
    "Pathology_results = pd.merge(pd.read_csv(f'./results/Path_RandomForest_{subset}.csv', header=0), label_data, on='ID', how='inner')\n",
    "Transformer_results = pd.merge(pd.read_csv(f'./results/Fusion_Transformer_{subset}.csv', header=0), label_data, on='ID', how='inner')\n",
    "\n",
    "ALL_results = pd.merge(pd.merge(Clinic_results, Habitat_results, on='ID', how='inner'),  Pathology_results, on='ID', how='inner')\n",
    "ALL_results = pd.merge(ALL_results, Transformer_results, on='ID', how='inner')\n",
    "\n",
    "ALL_results.columns = ['ID', '-0', model_names[0], task, \n",
    "                       '-00', model_names[1], '-l', \n",
    "                       '-000', model_names[2], '-ll',\n",
    "                       '-0000', model_names[-1], '-lll']\n",
    "ALL_results = normalize_df(ALL_results, not_norm=['ID'], method='minmax')\n",
    "Clinic = pd.read_csv('data/clinic_mul.csv')\n",
    "# Clinic['ID'] = Clinic['ID'].map(lambda x: f\"{x}.nii.gz\")\n",
    "Clinic = Clinic[[c for c in Clinic.columns if c not in ['label', 'group']]]\n",
    "ALL_results = pd.merge(ALL_results, Clinic, on='ID', how='inner')\n",
    "ALL_results = ALL_results.dropna(axis=1)\n",
    "ALL_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from onekey_algo.custom.components import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {}\n",
    "for mn, columns in zip(model_names[-5:-1], [list(Clinic.columns[1:]) + ['Habitat'],\n",
    "                                      list(Clinic.columns[1:]) + ['Pathology'], \n",
    "                                      ['Habitat', 'Pathology'],\n",
    "                                      list(Clinic.columns[1:]) + ['Habitat', 'Pathology']]):\n",
    "    model = LogisticRegression(penalty='l2', random_state=0, max_iter=100)\n",
    "#     model = SVC(probability=True, random_state=0)\n",
    "#     model = RandomForestClassifier(n_estimators=1, max_depth=None, min_samples_split=2, random_state=0)\n",
    "#     data_x = ALL_results[list(Clinic.columns[1:]) + model_names[:-1]]\n",
    "    data_x = ALL_results[columns]\n",
    "    data_y = ALL_results[task]\n",
    "    model.fit(data_x, data_y)\n",
    "    results = model.predict_proba(data_x)\n",
    "    results = pd.DataFrame(results, index=ALL_results['ID'], columns=[f'-0', f'{mn}']).reset_index()\n",
    "    results.to_csv(f'./results/{mn}_{subset}.csv', index=False, header=True)\n",
    "    ALL_results = pd.merge(ALL_results, results, on='ID', how='inner')\n",
    "    models[mn] = model\n",
    "ALL_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04731e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt = [np.array(ALL_results[task]) for d in model_names]\n",
    "pred_train = [np.array(ALL_results[d]) for d in model_names]\n",
    "okcomp.comp1.draw_roc(gt, pred_train, labels=model_names, title=f\"Model AUC\")\n",
    "plt.savefig(f'img/{subset}_auc.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.metrics import analysis_pred_binary\n",
    "metric = []\n",
    "youden = {}\n",
    "for mname, y, score in zip(model_names, gt, pred_train):\n",
    "    # 计算验证集指标\n",
    "    acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = analysis_pred_binary(y, score)\n",
    "    ci = f\"{ci[0]:.4f} - {ci[1]:.4f}\"\n",
    "    metric.append((mname, acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres, subset))\n",
    "    youden[mname] = thres\n",
    "pd.DataFrame(metric, index=None, columns=['Signature', 'Accuracy', 'AUC', '95% CI', 'Sensitivity', 'Specificity', \n",
    "                                          'PPV', 'NPV', 'Precision', 'Recall', 'F1','Threshold', 'Cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69899f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.delong import delong_roc_test\n",
    "from onekey_algo.custom.components.comp1 import draw_matrix\n",
    "\n",
    "delong = []\n",
    "delong_columns = []\n",
    "this_delong = []\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = np.zeros((len(model_names), len(model_names)))\n",
    "for i, mni in enumerate(model_names):\n",
    "    for j, mnj in enumerate(model_names):\n",
    "        if i <= j:\n",
    "            cm[i][j] = np.nan\n",
    "        else:\n",
    "            cm[i][j] = delong_roc_test(ALL_results[task], ALL_results[mni], ALL_results[mnj])[0][0]\n",
    "cm = pd.DataFrame(cm[1:, :-1], index=model_names[1:], columns=model_names[:-1])\n",
    "draw_matrix(cm, annot=True, cmap='jet_r', cbar=True)\n",
    "plt.title(f'Cohort {subset} Delong')\n",
    "plt.savefig(f'img/delong_each_cohort_{subset}.svg', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db27ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.delong import delong_roc_test\n",
    "from onekey_algo.custom.components.metrics import NRI, IDI\n",
    "\n",
    "delong = []\n",
    "delong_columns = []\n",
    "this_delong = []\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = np.zeros((len(model_names), len(model_names)))\n",
    "for i, mni in enumerate(model_names):\n",
    "    for j, mnj in enumerate(model_names):\n",
    "        cm[i][j] = NRI(ALL_results[mni] > youden[mni], ALL_results[mnj] > youden[mnj], ALL_results[task])\n",
    "cm = pd.DataFrame(cm, index=model_names, columns=model_names)\n",
    "draw_matrix(cm, annot=True, cmap='jet_r', cbar=True)\n",
    "plt.title(f'Cohort {subset} NRI')\n",
    "plt.savefig(f'img/all_NRI_each_cohort_{subset}.svg', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.delong import delong_roc_test\n",
    "from onekey_algo.custom.components.metrics import NRI, IDI\n",
    "\n",
    "delong = []\n",
    "delong_columns = []\n",
    "this_delong = []\n",
    "cm = np.zeros((len(model_names), len(model_names)))\n",
    "p = np.zeros((len(model_names), len(model_names)))\n",
    "for i, mni in enumerate(model_names):\n",
    "    for j, mnj in enumerate(model_names):\n",
    "        cm[i][j], p[i][j] = IDI(ALL_results[mni], ALL_results[mnj], ALL_results[task], with_p=True)\n",
    "\n",
    "for d, n in zip([cm, p], ['IDI', 'IDI pvalue']):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    d = pd.DataFrame(d, index=model_names, columns=model_names)\n",
    "    draw_matrix(d, annot=True, cmap='jet_r', cbar=True)\n",
    "    plt.title(f'Cohort {subset} {n}')\n",
    "    plt.savefig(f'img/all_{n}_each_cohort_{subset}.svg', bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.comp1 import plot_DCA\n",
    "plot_DCA([ALL_results[model_name] for model_name in model_names], \n",
    "         ALL_results[task], title=f'Model for DCA', labels=model_names, remap=True)\n",
    "plt.savefig(f'img/{subset}_dca.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c40079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.comp1 import draw_calibration\n",
    "draw_calibration(pred_scores=pred_train, n_bins=5, remap=True, add_1=True,\n",
    "                 y_test=gt, model_names=model_names)\n",
    "plt.savefig(f'img/{subset}_cali.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components import stats\n",
    "\n",
    "hosmer = []\n",
    "hosmer.append([stats.hosmer_lemeshow_test(y_true, y_pred, bins=100) \n",
    "              for fn, y_true, y_pred in zip(model_names, gt, pred_train)])\n",
    "pd.DataFrame(hosmer, columns=model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086a5f5",
   "metadata": {},
   "source": [
    "# 绘制Nomogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components import nomogram\n",
    "import shutil\n",
    "\n",
    "ALL_results = ALL_results.round(decimals=2)\n",
    "ALL_results.columns = [c.replace('+', '_') for c in ALL_results]\n",
    "nomogram.risk_nomogram(ALL_results, result=task, \n",
    "                       columns=list(Clinic.columns[1:]) + ['Habitat'], width=10000, height=4000,\n",
    "                      x_range='0.05,0.25,0.5,0.75,0.95')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd19d5c",
   "metadata": {},
   "source": [
    "# 测试集-Nomogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e08e9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import venn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from onekey_algo.custom.components import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "subset = 'test'\n",
    "for subset in [s for s in get_param_in_cwd('subsets') if s != 'train']:\n",
    "    Clinic_results = pd.merge(pd.read_csv(f'./results/Clinical_RandomForest_{subset}.csv', header=0), label_data, on='ID', how='inner')\n",
    "    Habitat_results = pd.merge(pd.read_csv(f'./results/Habitat_RandomForest_{subset}.csv', header=0), label_data, on='ID', how='inner')\n",
    "    Pathology_results = pd.merge(pd.read_csv(f'./results/Path_RandomForest_{subset}.csv', header=0), label_data, on='ID', how='inner')\n",
    "    Transformer_results = pd.merge(pd.read_csv(f'./results/Fusion_Transformer_{subset}.csv', header=0), label_data, on='ID', how='inner')\n",
    "\n",
    "    ALL_results = pd.merge(pd.merge(Clinic_results, Habitat_results, on='ID', how='inner'),  Pathology_results, on='ID', how='inner')\n",
    "    ALL_results = pd.merge(ALL_results, Transformer_results, on='ID', how='inner')\n",
    "\n",
    "    ALL_results.columns = ['ID', '-0', model_names[0], task, \n",
    "                           '-00', model_names[1], '-l', \n",
    "                           '-000', model_names[2], '-ll',\n",
    "                           '-0000', model_names[-1], '-lll']\n",
    "    ALL_results = normalize_df(ALL_results, not_norm=['ID'], method='minmax')\n",
    "    Clinic = pd.read_csv('data/clinic_mul.csv')\n",
    "    # Clinic['ID'] = Clinic['ID'].map(lambda x: f\"{x}.nii.gz\")\n",
    "    Clinic = Clinic[[c for c in Clinic.columns if c not in ['label', 'group']]]\n",
    "    ALL_results = pd.merge(ALL_results, Clinic, on='ID', how='inner')\n",
    "    ALL_results = ALL_results.dropna(axis=1)\n",
    "    ALL_results\n",
    "    \n",
    "    venn_labels = venn.generate_petal_labels([\n",
    "                                          set(Habitat_results['ID']),\n",
    "                                          set(Pathology_results['ID'])])\n",
    "    fig, ax = venn.venn2(venn_labels, names=['Radiomics', 'Pathology'], figsize=(10, 6))\n",
    "    fig.savefig(f'img/{subset}_venn_samples.svg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 计算融合模型\n",
    "    for mn, columns, model in zip(model_names[-5:-1], \n",
    "                                  [list(Clinic.columns[1:]) + ['Habitat'], \n",
    "                                   list(Clinic.columns[1:]) + ['Pathology'], \n",
    "                                   ['Habitat', 'Pathology'],\n",
    "                                   list(Clinic.columns[1:]) + ['Habitat', 'Pathology']],\n",
    "                                  models):\n",
    "\n",
    "        model = models[mn]\n",
    "    #     model = SVC(probability=True, random_state=0)\n",
    "    #     model = RandomForestClassifier(n_estimators=1, max_depth=3, min_samples_split=2, random_state=0)\n",
    "        data_x = ALL_results[columns]\n",
    "        data_y = ALL_results[task]\n",
    "        model.fit(data_x, data_y)\n",
    "        results = model.predict_proba(data_x)\n",
    "        results = pd.DataFrame(results, index=ALL_results['ID'], columns=[f'-0', f'{mn}']).reset_index()\n",
    "        results.to_csv(f'./results/{mn}_{subset}.csv', index=False, header=True)\n",
    "        ALL_results = pd.merge(ALL_results, results, on='ID', how='inner')\n",
    "    ALL_results\n",
    "    \n",
    "    # 绘制ROC\n",
    "    gt = [np.array(ALL_results[task]) for d in model_names]\n",
    "    pred_train = [np.array(ALL_results[d]) for d in model_names]\n",
    "    okcomp.comp1.draw_roc(gt, pred_train, labels=model_names, title=f\"Model AUC\")\n",
    "    plt.savefig(f'img/{subset}_auc.svg')\n",
    "    plt.show()\n",
    "    \n",
    "    # 输出Metrics\n",
    "    youden = {}\n",
    "    for mname, y, score in zip(model_names, gt, pred_train):\n",
    "        # 计算验证集指标\n",
    "        acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = analysis_pred_binary(y, score)\n",
    "        ci = f\"{ci[0]:.4f} - {ci[1]:.4f}\"\n",
    "        metric.append((mname, acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres, subset))\n",
    "        youden[mname] = thres\n",
    "    metric_ = pd.DataFrame(metric, index=None, columns=['Signature', 'Accuracy', 'AUC', '95% CI', 'Sensitivity', 'Specificity',                       \n",
    "                                                       'PPV', 'NPV', 'Precision', 'Recall', 'F1','Threshold', 'Cohort'])\n",
    "    display(metric_)\n",
    "    \n",
    "    # 计算Delong\n",
    "    delong = []\n",
    "    delong_columns = []\n",
    "    this_delong = []\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = np.zeros((len(model_names), len(model_names)))\n",
    "    for i, mni in enumerate(model_names):\n",
    "        for j, mnj in enumerate(model_names):\n",
    "            if i <= j:\n",
    "                cm[i][j] = np.nan\n",
    "            else:\n",
    "                cm[i][j] = delong_roc_test(ALL_results[task], ALL_results[mni], ALL_results[mnj])[0][0]\n",
    "    cm = pd.DataFrame(cm[1:, :-1], index=model_names[1:], columns=model_names[:-1])\n",
    "    draw_matrix(cm, annot=True, cmap='jet_r', cbar=True)\n",
    "    plt.title(f'Cohort {subset} Delong')\n",
    "    plt.savefig(f'img/delong_each_cohort_{subset}.svg', bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 计算NRI\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = np.zeros((len(model_names), len(model_names)))\n",
    "    for i, mni in enumerate(model_names):\n",
    "        for j, mnj in enumerate(model_names):\n",
    "            cm[i][j] = NRI(ALL_results[mni] > youden[mni], ALL_results[mnj] > youden[mnj], ALL_results[task])\n",
    "    cm = pd.DataFrame(cm, index=model_names, columns=model_names)\n",
    "    draw_matrix(cm, annot=True, cmap='jet_r', cbar=True)\n",
    "    plt.title(f'Cohort {subset} NRI')\n",
    "    plt.savefig(f'img/all_NRI_each_cohort_{subset}.svg', bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 计算IDI\n",
    "    cm = np.zeros((len(model_names), len(model_names)))\n",
    "    p = np.zeros((len(model_names), len(model_names)))\n",
    "    for i, mni in enumerate(model_names):\n",
    "        for j, mnj in enumerate(model_names):\n",
    "            cm[i][j], p[i][j] = IDI(ALL_results[mni], ALL_results[mnj], ALL_results[task], with_p=True)\n",
    "\n",
    "    for d, n in zip([cm, p], ['IDI', 'IDI pvalue']):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        d = pd.DataFrame(d, index=model_names, columns=model_names)\n",
    "        draw_matrix(d, annot=True, cmap='jet_r', cbar=True)\n",
    "        plt.title(f'Cohort {subset} {n}')\n",
    "        plt.savefig(f'img/all_{n}_each_cohort_{subset}.svg', bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # DCA\n",
    "    plot_DCA([ALL_results[model_name] for model_name in model_names], \n",
    "             ALL_results[task], title=f'Model for DCA', labels=model_names, remap=False, y_min=-0.15, \n",
    "#              EX={'n_estimators':5, 'max_depth': 1, 'random_state':0}, \n",
    "             idx_set=[3],\n",
    "            )\n",
    "    plt.savefig(f'img/{subset}_dca.svg')\n",
    "    \n",
    "    # 校准\n",
    "    draw_calibration(pred_scores=pred_train, n_bins=5, remap=True,\n",
    "                     #EX={'n_estimators':5, 'max_depth':4, 'random_state':0}, idx_set=[3],\n",
    "                     y_test=gt, model_names=model_names)\n",
    "    plt.savefig(f'img/{subset}_cali.svg')\n",
    "    \n",
    "    # HL\n",
    "    hosmer.append([stats.hosmer_lemeshow_test(y_true, y_pred, bins=19, remap=True, ) \n",
    "                   for fn, y_true, y_pred in zip(model_names, gt, pred_train)])\n",
    "    display(pd.DataFrame(hosmer, columns=model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62899a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from onekey_algo import init_CN\n",
    "\n",
    "init_CN()\n",
    "plt.rcParams['font.size'] = get_param_in_cwd('font.size', 20)\n",
    "plt.figure(figsize=(20, 14))\n",
    "sns.set_style(\"ticks\")\n",
    "metric = pd.DataFrame(metric, index=None, columns=['Signature', 'Accuracy', 'AUC', '95% CI', 'Sensitivity', 'Specificity',                       \n",
    "                                                       'PPV', 'NPV', 'Precision', 'Recall', 'F1','Threshold', 'Cohort'])\n",
    "\n",
    "def map_name(x):\n",
    "    if x == 'train':\n",
    "        return 'Train'\n",
    "    elif x == 'val':\n",
    "        return 'Internal Validation'\n",
    "    else:\n",
    "        return 'External Test'\n",
    "metric['Cohort'] = metric['Cohort'].map(lambda x: map_name(x))\n",
    "sns.barplot(x='Cohort', y='AUC', data=metric, hue='Signature')\n",
    "plt.ylim(0.5)\n",
    "plt.savefig('img/auc_comparision.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77cad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
